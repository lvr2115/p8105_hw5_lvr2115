---
title: "p8105_hw5_lvr2115"
author: "Laura Robles-Torres"
date: "2023-11-13"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(ggplot2)
library(rvest)
library(purrr)
```

 
## Problem 2

Import and tidy data

```{r import and tidy,message=FALSE,warning=FALSE}

raw_data = 
  tibble(
    files = list.files("./data"),
    path = str_c("./data/", files)
  ) |>
  mutate(data = map(path, read_csv)) |>
  unnest(data) 

tidy_data =
  raw_data |> 
   janitor::clean_names() |> 
   separate(files, sep="_", into = c("study_arm", "subject_id")) |>
   separate(subject_id, sep=".csv", into=c("subject_id")) |>
   mutate(study_arm = recode(study_arm, "con" = "Control", "exp" = "Experiment")) |>
   pivot_longer(
    cols = starts_with("week"),
    names_prefix = "week_",
    names_to = "week_num",
    values_to = "obs"
  ) |>
  mutate(
     week_num = as.numeric(week_num)) |>
  select(study_arm, subject_id, week_num, obs)
```

This spaghetti plot shows observations on each subject in the control and the experimental group over time. This plot shows that the experimental group's observed values increased as the study progressed from week 1 to week 8, showing a positive association between observed value and time. The control group's observed values range do not show this trend. The control group's observed values on week 8 are all lower than the experimental group's observed values on the same week. 

```{r plot}
ggplot(tidy_data, aes(x = week_num, y = obs , color = subject_id)) + 
  geom_point(alpha = .5) +
  geom_smooth(se = FALSE) + 
  facet_grid(. ~ study_arm) +
  labs(
    x = "Week", 
    y = "Observed value",
    title = "Changes in observed value per study arm over time",
    color = "Subject ID"
  ) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

## Problem 3


```{r}
# T-test function
sim_ttest = function(n=30, mu=0, sigma=5) {
  
  ttest_data = tibble(
    x=rnorm(n,mean=mu,sd=sigma),
  )

  ttest_data |>
    t.test(alpha=0.05) |>
    broom::tidy() |>
    select(estimate, p.value)
}
```

Testing 5000 samples with mean = 0 

```{r}
output = vector("list", 5000) 
#output: a list of 5000 values
for (i in 1:500) {
  output[[i]] = sim_ttest(mu=0) 
  #for loop: for each index in 1 to 100, im gonna have my output i = the simttest of mu=0
}

sim_result = bind_rows(output)
```

Simulation: mu {1 thru 6}
```{r}
sim_results_df =
  expand_grid(
    mean_size = 1:6,
    iteration = 1:5000) |>
  mutate(
    result = map(mean_size, sim_ttest)) |>
  unnest(result)

dim(sim_results_df)
head(sim_results_df)

```

# Power plot
This plot shows the proportion of times the null was rejected (the power of the test) on the y-axis and the true value of μ on the x axis.

Describe the association between effect size and power.


```{r}
sim_results_df
  group_by(mean) |>
  filter(p.value < 0.05) |>
  summarize(rejected_n = n()) |> 
    mutate(
      rejected_n = rejected_n / 5000) |>
  ggplot(aes(x = mean,y = rejected_n)) +
  geom_point() + geom_line()
  labs(
    x = "True mean",
    y = "Power",
    title = "Power - Different Means")
```


Make a plot showing the average estimate of μ̂ on the y axis and the true value of μ on the x axis.
Make a second plot (or overlay on the first) the average estimate of μ̂ only in samples for which the null was rejected on the y axis and the true value of μ on the x axis. Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ?
Why or why not?